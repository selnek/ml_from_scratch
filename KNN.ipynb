{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c25f62-88c7-419b-9786-bd87bbdd3358",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "KNN (K-Nearest Neighbors) is a machine learning algorithm used for classification and regression tasks. It is a non-parametric algorithm, which means that it does not make any assumptions about the distribution of the data.\n",
    "\n",
    "In KNN algorithm, the training dataset is used to create a model, which is then used to classify new data points. When a new data point is to be classified, the algorithm searches for the K nearest data points in the training set and assigns the class label based on the majority class among the K-nearest neighbors.\n",
    "\n",
    "The number K is a hyperparameter that needs to be specified prior to training the model. A small value of K may lead to overfitting, whereas a large value of K may lead to underfitting. Thus, choosing the appropriate value of K is crucial in achieving good performance.\n",
    "\n",
    "KNN algorithm can be used for both classification and regression tasks. For classification tasks, the output is a categorical variable, whereas for regression tasks, the output is a continuous variable.\n",
    "\n",
    "KNN algorithm is easy to implement and interpret, and can be used with any number of classes. However, it can be computationally expensive, especially when the size of the training dataset is large. Additionally, the algorithm can be sensitive to the choice of distance metric used to calculate the distance between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea35de-a1e5-4745-b429-a462c50c1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "        \n",
    "    def _predict(self, x):\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_idx = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_idx]\n",
    "        most_common = Counter(k_nearest_labels).most_common()\n",
    "        return most_common[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40f926-bfe2-4f1e-9491-4828ce118f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = KNN(k=5)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "acc = np.sum(predictions == y_test) / len(y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4d740-7312-40ac-bd05-6c2c9ec27b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
